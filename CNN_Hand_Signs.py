# -*- coding: utf-8 -*-
"""convolutional-neural-network-cnn-mnist-sign-lang.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OxV-lGz9BbbG8KrxhjzsVJA1Tlr5F5Sx

# Convolutional Neural Network (CNN)

<font color="blue">**Content:** </font>
    * [Loading the Data Set](#2)
    * [Normalization, Reshape and Label Encoding](#3)
    * [Train Test Split](#4)

---

When you upload an image to Facebook, you ask "Do you want to tag the X person?" makes a proposition. So did you wonder how you knew that person?
Or have you ever thought how Google's image search algorithm works?
There is a neural network behind all this. To be more precise, we are talking about the Convolutional Neural Network (ConvNet or CNN). . While CNN may seem like a strange mixture of biology and computer science, this is a very effective mechanism used for image recognition.
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

"""# Loading the Data Set <a id="2"></a>
* In this part we load and visualize the data.

"""

from google.colab import drive
drive.mount('/content/drive')

train_df = pd.read_csv("/content/drive/MyDrive/Machine_Learning/sign_mnist_train.csv")
train_df.head()

pd.DataFrame({
    'X': ['Train Shape','Different number of labels','Different number of labels (Sum)' ],
    'Y': [train_df.shape, train_df.label.unique(), len(train_df.label.unique())],
})

test_df = pd.read_csv("/content/drive/MyDrive/Machine_Learning/sign_mnist_test.csv")
print("Test Shape: ", test_df.shape)
test_df.head()

my_circle = plt.Circle( (0,0), 0.7, color='white')
plt.pie([len(train_df),len(test_df)], labels=["Train","Test"], colors=['green','skyblue'])
p = plt.gcf()
p.gca().add_artist(my_circle)
plt.show()

# I synchronize the numbers it represents to a variable in the form of an array

Y_train = train_df['label']
Y_test = test_df['label']

X_train = train_df.drop(["label"],axis=1)
X_test = test_df.drop(["label"],axis=1)

# del train_df['label']
# del test_df['label']

plt.figure(figsize=(15, 7))
g = sns.countplot(x=Y_train, palette="icefire")
plt.title("Number of Digit Classes")
plt.xlabel("Label")
plt.ylabel("Count")
plt.show()

f, ax = plt.subplots(2,4)
f.set_size_inches(8,8)

k = 0
for i in range(2):
    for j in range(4):
        img = X_train.iloc[k].to_numpy()
        img = img.reshape((28,28))
        ax[i,j].set_xlabel(chr(Y_train[k] + 65))
        ax[i,j].imshow(img,cmap='gray')
        k += 1
    plt.tight_layout()

"""# Normalization, Reshape and Label Encoding <a id="3"></a>
* **Normalization**
    * We perform a grayscale normalization to reduce the effect of illumination's differences.
    * If we perform normalization, CNN works faster.
* **Reshape**
    * Train and test images (28 x 28)
    * We reshape all data to 28x28x1 3D matrices.
    * Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel.
* **Label Encoding**
    * Encode labels to one hot vectors
        * 2 => [0,0,1,0,0,0,0,0,0,0]
        * 4 => [0,0,0,0,1,0,0,0,0,0]

"""

# normalize the data
X_train = X_train/255.0
X_test = X_test/255.0
print("X_train shape: ",X_train.shape)
print("X_test shape: ",X_test.shape)

# reshape
X_train = X_train.values.reshape(-1,28,28,1)
X_test = X_test.values.reshape(-1,28,28,1)
print("X_train shape: ",X_train.shape)
print("X_test shape: ",X_test.shape)

# label encoding
from sklearn.preprocessing import LabelBinarizer
label_binrizer = LabelBinarizer()
Y_train = label_binrizer.fit_transform(Y_train)

"""# Train Test Split <a id="4"></a>
* We split the data into train and test (for validation only) sets.
* validation size is 15%
* train size is 85%
"""

from sklearn.model_selection import train_test_split
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)

print("x_train shape",X_train.shape)
print("x_val shape",X_val.shape)
print("y_train shape",Y_train.shape)
print("y_val shape",Y_val.shape)

plt.imshow(X_train[20][:,:,0],cmap="gray")
plt.show()

from sklearn.metrics import confusion_matrix
import itertools

from keras.utils import to_categorical # convert to one-hot-encoding
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from keras.optimizers import RMSprop,Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau

model = Sequential()

model.add(Conv2D(filters=75 , kernel_size=(3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))
model.add(MaxPool2D(pool_size=(2,2), strides = 2 , padding = 'same'))

model.add(Conv2D(filters=50, kernel_size=(3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(MaxPool2D(pool_size=(2,2), strides = 2 , padding = 'same'))

model.add(Conv2D(filters=25, kernel_size=(3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(MaxPool2D(pool_size=(2,2) , strides = 2 , padding = 'same'))

model.add(Flatten())

model.add(Dense(units = 512 , activation = 'relu'))
model.add(Dropout(0.2))

model.add(Dense(units = 24 , activation = 'softmax'))
model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])
model.summary()

optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999)

model.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])

epochs = 200  # for better result increase the epochs
batch_size = 200

from keras.callbacks import EarlyStopping, ModelCheckpoint

# Stop training when a monitored quantity has stopped improving
early_stopping = EarlyStopping(
    monitor='val_loss',    # Could be 'val_loss' or 'val_accuracy' or any other metric you're monitoring
    patience=10,           # Number of epochs with no improvement after which training will be stopped
    verbose=1              # Verbosity mode
)

# Save the model after every epoch
model_checkpoint = ModelCheckpoint(
    'best_model.h5',       # Path where the model will be saved
    monitor='val_loss',    # Could be 'val_loss' or 'val_accuracy' or any other metric you're monitoring
    save_best_only=True,   # Save only the best model (according to the monitored metric)
    verbose=1              # Verbosity mode
)

# data augmentation
datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # dimesion reduction
        rotation_range=15,  # randomly rotate images in the range 15 degrees
        zoom_range = 0.5, # Randomly zoom image 5%
        width_shift_range=0.15,  # randomly shift images horizontally 15%
        height_shift_range=0.15,  # randomly shift images vertically 15%
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images

datagen.fit(X_train)

history = model.fit(
    datagen.flow(X_train, Y_train, batch_size=batch_size),
    epochs=epochs,
    validation_data=(X_val, Y_val),
    steps_per_epoch=X_train.shape[0] // batch_size,
    callbacks=[early_stopping, model_checkpoint]
)

"""### fit() & fit_genarator()
* In keras, fit() is much similar to sklearn's fit method, where you pass array of features as x values and target as y values. You pass your whole dataset at once in fit method. Also, use it if you can load whole data into your memory (small dataset).
* In fit_generator(), you don't pass the x and y directly, instead they come from a generator. As it is written in keras documentation, generator is used when you want to avoid duplicate data when using multiprocessing. This is for practical purpose, when you have large dataset.

### Dropout
* It prevents over learning.
* It increases diversity.

### Epoch & Batch & Number of Iteration
* **one epoch: ** one forward pass and one backward pass of all the training examples
* **batch size:** the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.
* **number of iterations:** number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).

Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.
"""

fig , ax = plt.subplots(1,2)
train_acc = history.history['accuracy']
train_loss = history.history['loss']
fig.set_size_inches(12,4)

ax[0].plot(history.history['accuracy'])
ax[0].plot(history.history['val_accuracy'])
ax[0].set_title('Training Accuracy vs Validation Accuracy')
ax[0].set_ylabel('Accuracy')
ax[0].set_xlabel('Epoch')
ax[0].legend(['Train', 'Validation'], loc='upper left')

ax[1].plot(history.history['loss'])
ax[1].plot(history.history['val_loss'])
ax[1].set_title('Training Loss vs Validation Loss')
ax[1].set_ylabel('Loss')
ax[1].set_xlabel('Epoch')
ax[1].legend(['Train', 'Validation'], loc='upper left')

plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
# Predict the values from the validation dataset
Y_pred_prob = model.predict(X_test)

Y_pred = np.argmax(Y_pred_prob, axis=1)
for i in range(len(Y_pred)):
    if(Y_pred[i] >= 9):
        Y_pred[i] += 1
Y_pred[:5]

# Find unique labels present in the dataset
unique_labels = np.unique(np.concatenate((Y_true, Y_pred)))
# compute the confusion matrix
confusion_mtx = confusion_matrix(Y_test, Y_pred)
confusion_mtx = pd.DataFrame(confusion_mtx , index = [i for i in range(25) if i != 9] , columns = [i for i in range(25) if i != 9])
# plot the confusion matrix
f,ax = plt.subplots(figsize=(16, 12))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Blues",fmt= 'd',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Generate classification report
classes = ["Class " + str(i) for i in range(25) if i != 9]
print(classification_report(Y_test, Y_pred, target_names = classes))

# Select the indices for the test scenarios
test_indices = [0, 1, 2, 3, 4]

# Plot the images with their true and predicted labels
plt.figure(figsize=(15, 7))

for i, idx in enumerate(test_indices):
    plt.subplot(1, 5, i+1)
    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')  # Adjust the shape based on your image shape
    plt.title(f"True: {chr(Y_test[idx] + 65)}\nPred: {chr(Y_pred[idx] + 65)}")
    plt.axis('off')

plt.show()